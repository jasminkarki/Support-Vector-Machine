{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# df=pd.read_csv('sentiment_5_class.csv')\n",
    "train_df=pd.read_csv('sentiment_5_class_train.csv')\n",
    "test_df=pd.read_csv('sentiment_5_class_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14711, 2)\n",
      "(3678, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of instances 14711 3678\n",
      "[0 1 2 3 4] [0 1 2 3 4]\n",
      "[ 988 1165 1876 7033 3649] [ 247  291  469 1759  912]\n"
     ]
    }
   ],
   "source": [
    "X_train=train_df.Phrase.tolist()\n",
    "X_test=test_df.Phrase.tolist()\n",
    "\n",
    "print('No of instances',len(X_train), len(X_test))\n",
    "y_train=train_df.Sentiment.tolist()\n",
    "y_test =test_df.Sentiment.tolist()\n",
    "values_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "values_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "print(values_train, values_test)\n",
    "print(counts_train, counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_train))\n",
    "# print(len(X_test))\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "**Binary Feature Vectorization<br>\n",
    "Count Feature Vectorization<br>\n",
    "TF-IDF Feature Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:  \n",
    "By default, Regex is +.  So, Single alphabet is ignored \n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into vector is done only by transform\n",
    "['am', 'happy', 'i', 'sad', 'so']\n",
    "and its respective frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am', 'happy', 'i', 'sad', 'so']\n",
      "['am', 'happy', 'i', 'sad', 'so']\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 2, 0],\n",
       "       [1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['Happy, happy','I am so happy','Sad sad', 'I am so sad']\n",
    "c_vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b')\n",
    "t_vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b')\n",
    "\n",
    "c_vectorizer.fit(data)\n",
    "print(c_vectorizer.get_feature_names())\n",
    "\n",
    "t_vectorizer.fit(data)\n",
    "print(t_vectorizer.get_feature_names())\n",
    "\n",
    "print(c_vectorizer)\n",
    "\n",
    "c_data_v=c_vectorizer.transform(data)  #Vector conversion\n",
    "c_data_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am', 'happy', 'sad', 'so']\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.57735027 0.57735027 0.         0.57735027]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.57735027 0.         0.57735027 0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "t_vectorizer = TfidfVectorizer()  # (token pattern ='(?u)\\\\b\\\\w\\\\w*\\\\b')\n",
    "t_vectorizer.fit(data)\n",
    "print(t_vectorizer.get_feature_names())\n",
    "\n",
    "print(t_vectorizer)\n",
    "\n",
    "t_data_v=t_vectorizer.transform(data)\n",
    "print(t_data_v.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer VS TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7115\n",
      "7115\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Fit should be done only on training data BE CAREFULLLLL\n",
    "count_vectorizer.fit(X_train)\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "print(len(count_vectorizer.get_feature_names()))\n",
    "print(len(tfidf_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14711, 7115) (3678, 7115)\n"
     ]
    }
   ],
   "source": [
    "# COUNT VECTORIZER\n",
    "X_train_count_v=count_vectorizer.transform(X_train)\n",
    "X_test_count_v= count_vectorizer.transform(X_test)\n",
    "\n",
    "#TF-IDF VECTORIZER\n",
    "X_train_tfidf_v=tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf_v=tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_count_v.shape, X_test_count_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "grid_param={'kernel':('linear','rbf'),'C':(10,20)}\n",
    "\n",
    "# ,'gamma':[1,0.1,0.01,0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "def SVM_Model(X_train,X_test,y_train,y_test,grid):\n",
    "    model=SVC()\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    global i\n",
    "    vectors=['Count Vectorizer','TF-IDF Vectorizer']\n",
    "    print('Classification Report with {} \\n '.format(vectors[i]))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    scorer=make_scorer(f1_score,average='micro')\n",
    "    clf=GridSearchCV(SVC(),grid_param,scoring=scorer)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print('Best Score',clf.best_score_,'with',clf.best_params_)\n",
    "    x=clf.best_params_\n",
    "    \n",
    "    model=SVC(kernel=x['kernel'],C=x['C'],random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print('AUC ROC Score', roc_auc_score(y_pred, y_test))\n",
    "    vectors=['Count Vectorizer','TF-IDF Vectorizer']\n",
    "    print('\\tClassification Report of best feature with {} \\n'.format(vectors[i]))\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Count Vectorizer \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.45      0.57       247\n",
      "           1       0.62      0.30      0.40       291\n",
      "           2       0.78      0.20      0.32       469\n",
      "           3       0.60      0.91      0.73      1759\n",
      "           4       0.76      0.52      0.62       912\n",
      "\n",
      "    accuracy                           0.64      3678\n",
      "   macro avg       0.71      0.48      0.53      3678\n",
      "weighted avg       0.68      0.64      0.61      3678\n",
      "\n",
      "Best Score 0.6987284810677747 with {'C': 10, 'kernel': 'rbf'}\n",
      "\tClassification Report of best feature with Count Vectorizer \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       247\n",
      "           1       0.63      0.56      0.59       291\n",
      "           2       0.70      0.72      0.71       469\n",
      "           3       0.74      0.80      0.77      1759\n",
      "           4       0.71      0.64      0.67       912\n",
      "\n",
      "    accuracy                           0.72      3678\n",
      "   macro avg       0.71      0.68      0.69      3678\n",
      "weighted avg       0.72      0.72      0.72      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_Model(X_train_count_v,X_test_count_v,y_train,y_test,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with TF-IDF Vectorizer \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.55      0.65       247\n",
      "           1       0.64      0.44      0.52       291\n",
      "           2       0.74      0.52      0.61       469\n",
      "           3       0.68      0.89      0.77      1759\n",
      "           4       0.78      0.58      0.66       912\n",
      "\n",
      "    accuracy                           0.71      3678\n",
      "   macro avg       0.73      0.60      0.64      3678\n",
      "weighted avg       0.72      0.71      0.70      3678\n",
      "\n",
      "Best Score 0.6977766782555387 with {'C': 10, 'kernel': 'rbf'}\n",
      "\tClassification Report of best feature with TF-IDF Vectorizer \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       247\n",
      "           1       0.64      0.54      0.58       291\n",
      "           2       0.71      0.63      0.67       469\n",
      "           3       0.73      0.80      0.76      1759\n",
      "           4       0.69      0.65      0.67       912\n",
      "\n",
      "    accuracy                           0.71      3678\n",
      "   macro avg       0.70      0.66      0.68      3678\n",
      "weighted avg       0.71      0.71      0.71      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_Model(X_train_tfidf_v,X_test_tfidf_v,y_train,y_test,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=SVC(kernel='rbf',C=10,random_state=1)\n",
    "# model.fit(X_train_count_v,y_train)\n",
    "# y_pred = model.predict(X_test_count_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors=['Count Vectorizer','TF-IDF Vectorizer']\n",
    "# for i in range(2):\n",
    "#     plt.figure(figsize=(6,6))\n",
    "#     clf_report = metrics.classification_report(y_test,y_pred,output_dict=True)\n",
    "#     sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n",
    "#     plt.title('Classification Report of best feature of SVM with {} \\n '.format(vectors[i]))\n",
    "\n",
    "#     plt.xlabel('Evaluation Metrics')\n",
    "#     plt.ylabel('Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=SVC()\n",
    "# model.fit(X_train_v,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "# # There are three classes [0,1,2]\n",
    "# a_true = [1,1,1]\n",
    "# a_pred = [1,1,0]\n",
    "\n",
    "# # Confusion matrix\n",
    "# # [0, 0, 0\n",
    "# #  1, 2, 0\n",
    "# #  0, 0, 0]\n",
    "\n",
    "# TP_0 = 0\n",
    "# FP_0 = 1\n",
    "# Precision_0 = 0\n",
    "\n",
    "# TP_1 = 0\n",
    "# FP_1 = 1\n",
    "# Precision_1 = 1\n",
    "\n",
    "# TP_2 = 0\n",
    "# FP_2 = 0\n",
    "# Precision_2 = 0\n",
    "\n",
    "# macro_precision = (Precision_0 + Precision_1 + Precision_2)/3\n",
    "# print(macro_precision)\n",
    "\n",
    "# #Preferred\n",
    "# micro_precision = (TP_0 + TP_1 + TP_2)/(TP_0 + FP_0 + TP_1 + FP_1 + TP_2 + FP_2)\n",
    "# print(micro_precision)\n",
    "\n",
    "# weight_precision = (Precision_0*0 + Precision_1*3 + Precision_2*0)/(0+3+0)\n",
    "# print(weight_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics.classification_report(a_true, a_pred, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test_v)\n",
    "# print('Classification Report with Count Vectorizer')\n",
    "# print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [1,2,3,4,5,6,7,8,9,10]  #X_train and test\n",
    "# y = [1,0,0,0,1,1,1,1,1,0]   #y_train and test\n",
    "\n",
    "# # k fold cross validation\n",
    "# K = 5\n",
    "# x_1 = [1, 2]\n",
    "# y_1 = [1, 0]\n",
    "\n",
    "# x_2 = [3, 4]\n",
    "# y_2 = [0, 0]\n",
    "\n",
    "# x_3 = [5, 6]\n",
    "# y_3 = [1, 1]\n",
    "\n",
    "# x_4 = [7, 8]\n",
    "# y_4 = [1, 1]\n",
    "\n",
    "# x_5 = [9, 10]\n",
    "# y_5 = [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "\n",
    "# a=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# b=np.array([1,1,1,1,3,0,0,2,2,3])\n",
    "\n",
    "# k=2\n",
    "# skf=KFold(n_splits=k, shuffle=True,random_state=1)\n",
    "\n",
    "# for train_index, test_index in skf.split(a,b):\n",
    "#     print(a[train_index],b[train_index])\n",
    "#     print(a[test_index],b[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# a=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# b=np.array([1,1,1,1,3,0,0,2,2,3])\n",
    "\n",
    "# k=2\n",
    "\n",
    "# skf=StratifiedKFold(n_splits=k, shuffle=True,random_state=1)\n",
    "\n",
    "\n",
    "# for train_index, test_index in skf.split(a,b):\n",
    "#     print(a[train_index],b[train_index])\n",
    "#     print(a[test_index],b[test_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
