{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "df=pd.read_csv('sentiment_5_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>injects just enough freshness into the proceed...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>never plays as dramatic even when dramatic thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None of this is very original , and it is n't ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, Madonna gives her best performance since Abe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18384</th>\n",
       "      <td>to balance pointed , often incisive satire and...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18385</th>\n",
       "      <td>have to be a most hard-hearted person not to b...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18386</th>\n",
       "      <td>could young romantics out on a date</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18387</th>\n",
       "      <td>could be this good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18388</th>\n",
       "      <td>such a dungpile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18389 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Phrase  Sentiment\n",
       "0      injects just enough freshness into the proceed...          3\n",
       "1                                                   that          2\n",
       "2      never plays as dramatic even when dramatic thi...          0\n",
       "3      None of this is very original , and it is n't ...          0\n",
       "4      , Madonna gives her best performance since Abe...          3\n",
       "...                                                  ...        ...\n",
       "18384  to balance pointed , often incisive satire and...          3\n",
       "18385  have to be a most hard-hearted person not to b...          4\n",
       "18386                could young romantics out on a date          3\n",
       "18387                                 could be this good          3\n",
       "18388                                    such a dungpile          0\n",
       "\n",
       "[18389 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "Dataset split in train and test set\n",
    "KFold Cross Validation used to determine hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of instances 18389\n",
      "[0 1 2 3 4]\n",
      "[1235 1456 2345 8792 4561]\n"
     ]
    }
   ],
   "source": [
    "X=df.Phrase.tolist()\n",
    "print('No of instances',len(X))\n",
    "y=df.Sentiment.tolist()\n",
    "values, counts = np.unique(y, return_counts=True)\n",
    "print(values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14711\n",
      "3678\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "**Binary Feature Vectorization<br>\n",
    "Count Feature Vectorization<br>\n",
    "TF-IDF Feature Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorizer(vectorizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['Happy, happy','I am so happy','Sad sad', 'I am so sad']\n",
    "c_vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b')\n",
    "t_vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am', 'happy', 'i', 'sad', 'so']\n",
      "['am', 'happy', 'i', 'sad', 'so']\n"
     ]
    }
   ],
   "source": [
    "c_vectorizer.fit(data)\n",
    "print(c_vectorizer.get_feature_names())\n",
    "\n",
    "t_vectorizer.fit(data)\n",
    "print(t_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 2, 0],\n",
       "       [1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_data_v=c_vectorizer.transform(data)  #Vector conversion\n",
    "\n",
    "c_data_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w*\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into vector is done only by transform\n",
    "['am', 'happy', 'i', 'sad', 'so']\n",
    "and its respective frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'happy', 'sad', 'so']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vectorizer = TfidfVectorizer()  # (token pattern ='(?u)\\\\b\\\\w\\\\w*\\\\b')\n",
    "t_vectorizer.fit(data)\n",
    "t_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.57735027]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data_v=t_vectorizer.transform(data)\n",
    "t_data_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer VS TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Fit should be done only on training data BE CAREFULLLLL\n",
    "count_vectorizer.fit(X_train)\n",
    "tfidf_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT VECTORIZER\n",
    "X_train_count_v=count_vectorizer.transform(X_train)\n",
    "X_test_count_v= count_vectorizer.transform(X_test)\n",
    "\n",
    "#TF-IDF VECTORIZER\n",
    "X_train_tfidf_v=tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf_v=tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "grid_param={'kernel':('linear','rbf'),'C':(1,10)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "def SVM_Model(X_train,X_test,y_train,y_test,grid):\n",
    "    model=SVC()\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    global i\n",
    "    vectors=['Count Vectorizer','TF-IDF Vectorizer']\n",
    "    print('Classification Report with {} \\n '.format(vectors[i]))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    scorer=make_scorer(f1_score,average='micro')\n",
    "    clf=GridSearchCV(SVC(),grid_param,scoring=scorer)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print('Best Score',clf.best_score_,'with',clf.best_params_)\n",
    "    x=clf.best_params_\n",
    "    \n",
    "    model=SVC(kernel=x['kernel'],C=x['C'],random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    vectors=['Count Vectorizer','TF-IDF Vectorizer']\n",
    "    print('\\tClassification Report of best feature with {} \\n'.format(vectors[i]))\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Count Vectorizer \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.49      0.62       247\n",
      "           1       0.69      0.31      0.43       291\n",
      "           2       0.68      0.23      0.34       469\n",
      "           3       0.61      0.91      0.73      1759\n",
      "           4       0.77      0.51      0.62       912\n",
      "\n",
      "    accuracy                           0.65      3678\n",
      "   macro avg       0.72      0.49      0.55      3678\n",
      "weighted avg       0.68      0.65      0.62      3678\n",
      "\n",
      "Best Score 0.7002919739727378 with {'C': 10, 'kernel': 'rbf'}\n",
      "\tClassification Report of best feature with Count Vectorizer \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69       247\n",
      "           1       0.64      0.55      0.59       291\n",
      "           2       0.66      0.73      0.69       469\n",
      "           3       0.73      0.79      0.76      1759\n",
      "           4       0.69      0.59      0.64       912\n",
      "\n",
      "    accuracy                           0.71      3678\n",
      "   macro avg       0.70      0.66      0.67      3678\n",
      "weighted avg       0.70      0.71      0.70      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_Model(X_train_count_v,X_test_count_v,y_train,y_test,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with TF-IDF Vectorizer \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.54      0.66       247\n",
      "           1       0.70      0.47      0.56       291\n",
      "           2       0.67      0.51      0.58       469\n",
      "           3       0.67      0.88      0.76      1759\n",
      "           4       0.79      0.55      0.65       912\n",
      "\n",
      "    accuracy                           0.70      3678\n",
      "   macro avg       0.73      0.59      0.64      3678\n",
      "weighted avg       0.71      0.70      0.69      3678\n",
      "\n",
      "Best Score 0.6938339439608625 with {'C': 10, 'kernel': 'rbf'}\n",
      "\tClassification Report of best feature with TF-IDF Vectorizer \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       247\n",
      "           1       0.68      0.58      0.62       291\n",
      "           2       0.65      0.63      0.64       469\n",
      "           3       0.72      0.81      0.76      1759\n",
      "           4       0.71      0.61      0.65       912\n",
      "\n",
      "    accuracy                           0.71      3678\n",
      "   macro avg       0.70      0.66      0.68      3678\n",
      "weighted avg       0.71      0.71      0.70      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_Model(X_train_tfidf_v,X_test_tfidf_v,y_train,y_test,grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SVC()\n",
    "model.fit(X_train_v,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# There are three classes [0,1,2]\n",
    "a_true = [1,1,1]\n",
    "a_pred = [1,1,0]\n",
    "\n",
    "# Confusion matrix\n",
    "# [0, 0, 0\n",
    "#  1, 2, 0\n",
    "#  0, 0, 0]\n",
    "\n",
    "TP_0 = 0\n",
    "FP_0 = 1\n",
    "Precision_0 = 0\n",
    "\n",
    "TP_1 = 0\n",
    "FP_1 = 1\n",
    "Precision_1 = 1\n",
    "\n",
    "TP_2 = 0\n",
    "FP_2 = 0\n",
    "Precision_2 = 0\n",
    "\n",
    "macro_precision = (Precision_0 + Precision_1 + Precision_2)/3\n",
    "print(macro_precision)\n",
    "\n",
    "#Preferred\n",
    "micro_precision = (TP_0 + TP_1 + TP_2)/(TP_0 + FP_0 + TP_1 + FP_1 + TP_2 + FP_2)\n",
    "print(micro_precision)\n",
    "\n",
    "weight_precision = (Precision_0*0 + Precision_1*3 + Precision_2*0)/(0+3+0)\n",
    "print(weight_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80         3\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.67      0.67      0.67         3\n",
      "   macro avg       0.33      0.22      0.27         3\n",
      "weighted avg       1.00      0.67      0.80         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkarki/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkarki/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(a_true, a_pred, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.54      0.66       247\n",
      "           1       0.70      0.47      0.56       291\n",
      "           2       0.67      0.51      0.58       469\n",
      "           3       0.67      0.88      0.76      1759\n",
      "           4       0.79      0.55      0.65       912\n",
      "\n",
      "    accuracy                           0.70      3678\n",
      "   macro avg       0.73      0.59      0.64      3678\n",
      "weighted avg       0.71      0.70      0.69      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_v)\n",
    "print('Classification Report with Count Vectorizer')\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9,10]  #X_train and test\n",
    "y = [1,0,0,0,1,1,1,1,1,0]   #y_train and test\n",
    "\n",
    "# k fold cross validation\n",
    "K = 5\n",
    "x_1 = [1, 2]\n",
    "y_1 = [1, 0]\n",
    "\n",
    "x_2 = [3, 4]\n",
    "y_2 = [0, 0]\n",
    "\n",
    "x_3 = [5, 6]\n",
    "y_3 = [1, 1]\n",
    "\n",
    "x_4 = [7, 8]\n",
    "y_4 = [1, 1]\n",
    "\n",
    "x_5 = [9, 10]\n",
    "y_5 = [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6 8 9] [1 1 0 2 2]\n",
      "[ 1  3  5  7 10] [1 1 3 0 3]\n",
      "[ 1  3  5  7 10] [1 1 3 0 3]\n",
      "[2 4 6 8 9] [1 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "a=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "b=np.array([1,1,1,1,3,0,0,2,2,3])\n",
    "\n",
    "k=2\n",
    "skf=KFold(n_splits=k, shuffle=True,random_state=1)\n",
    "\n",
    "for train_index, test_index in skf.split(a,b):\n",
    "    print(a[train_index],b[train_index])\n",
    "    print(a[test_index],b[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  7  9 10] [1 1 0 2 3]\n",
      "[3 4 5 6 8] [1 1 3 0 2]\n",
      "[3 4 5 6 8] [1 1 3 0 2]\n",
      "[ 1  2  7  9 10] [1 1 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "a=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "b=np.array([1,1,1,1,3,0,0,2,2,3])\n",
    "\n",
    "k=2\n",
    "\n",
    "skf=StratifiedKFold(n_splits=k, shuffle=True,random_state=1)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(a,b):\n",
    "    print(a[train_index],b[train_index])\n",
    "    print(a[test_index],b[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': ('linear', 'rbf'), 'C': (1, 10)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_param={'kernel':('linear','rbf'),'C':(1,10)}\n",
    "grid_param\n",
    "\n",
    "#Makes a combination [linear,1],[linear,10],[rbf,1],[rbf,10]\n",
    "\n",
    "#[linear,1] --> 5 fold stratified cross validation, average_val_loss_calculate\n",
    "#[linear,10] --> 5 fold cross validation, average_val_loss_calculate\n",
    "#[rbf,1] --> 5 fold cross validation, average_val_loss_calculate\n",
    "#[rbf,10] --> 5 fold cross validation, average_val_loss_calculate\n",
    "\n",
    "\n",
    "#Define scorer in scoring=None for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "scorer=make_scorer(f1_score,average='micro')\n",
    "clf=GridSearchCV(SVC(),grid_param,scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': (1, 10), 'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(f1_score, average=micro), verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf=GridSearchCV(SVC(),grid_param)\n",
    "clf.fit(X_train_v,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6938339439608625 {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_,clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       247\n",
      "           1       0.68      0.58      0.62       291\n",
      "           2       0.65      0.63      0.64       469\n",
      "           3       0.72      0.81      0.76      1759\n",
      "           4       0.71      0.61      0.65       912\n",
      "\n",
      "    accuracy                           0.71      3678\n",
      "   macro avg       0.70      0.66      0.68      3678\n",
      "weighted avg       0.71      0.71      0.70      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final Model\n",
    "\n",
    "model=SVC(random_state=1,kernel='rbf',C=10)\n",
    "model.fit(X_train_v,y_train)\n",
    "y_pred=model.predict(X_test_v)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65       247\n",
      "           1       0.63      0.47      0.54       291\n",
      "           2       0.65      0.51      0.57       469\n",
      "           3       0.68      0.86      0.76      1759\n",
      "           4       0.75      0.56      0.64       912\n",
      "\n",
      "    accuracy                           0.69      3678\n",
      "   macro avg       0.70      0.59      0.63      3678\n",
      "weighted avg       0.69      0.69      0.68      3678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=SVC(random_state=1,kernel='linear',C=1)\n",
    "model.fit(X_train_v,y_train)\n",
    "y_pred=model.predict(X_test_v)\n",
    "print(metrics.classification_report(y_test,y_pred))\n",
    "\n",
    "#Report the f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
